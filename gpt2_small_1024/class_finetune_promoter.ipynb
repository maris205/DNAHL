{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c50df10-e541-4828-9ecd-65fb2c0a8290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "# 打印环境变量以确认设置成功\n",
    "print(os.environ.get('HF_ENDPOINT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29888eda-2755-4add-af9c-8927afb07db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 19:37:08.143082: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-18 19:37:08.155839: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-18 19:37:08.170783: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-18 19:37:08.175307: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-18 19:37:08.186905: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-18 19:37:09.079539: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tokenizers import Tokenizer\n",
    "from transformers import GPT2LMHeadModel, AutoConfig,GPT2Tokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da089a13-0b56-4b04-b003-92fd7669a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"dnagpt/dna_eng_bpe\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75e3778d-9cbb-48c4-8203-0f71f485a49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt_dna_eng_v1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('gpt_dna_eng_v1', num_labels=2)\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde9ebbc-06a9-4550-a97a-ca785fbe2251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50000, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd024199-16e6-4eb1-b404-c49dc535469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# load ~11k samples from promoters prediction dataset\n",
    "dataset = load_dataset(\"dnagpt/dna_promoters\")['train'].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3a5213d-66f0-4d17-876c-de4426145412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sequence', 'promoter_presence'],\n",
       "        num_rows: 10656\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sequence', 'promoter_presence'],\n",
       "        num_rows: 1184\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36a23870-1f56-466e-b2bb-c5047072b8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'GGGCTCAGAGACTGGGTTTGTTTTGGGGAGTCTGCACCTATTTGCTGAGTGAATGTATGTGTGTGTGCATTTGAGAGCACACCTCTGTATGATTCGGGTGTGAGTGTGTGTGAGGAAACGTGGGCAGGCGAGGAGTGTTTGGGAGCCAGGTGCAGCTGGGGTGTGAGTGTGTAAGCAAGCAGCTATGAGGCTGGGCATTGCTTCTCCTCCTCTTCTCCAGCTCCCAGCCTTTCTTCCCCGGGACTCCTGGGGCTCCAGGATGCCCCCAAGATCCCCTCCACAAGTGGATAATTTGGGCTGCCTTGTCTGACCCTCCAATTATACACTCCTTTGCCTCTTTCCGTCATTCCATAACCACCCAACCCCTACTCCACCGGGAGGGGGTTGGGCATACCTGGATCCACCCCGTTTCTGGGGGGTGAGCGGGGCTTGGCAGGGCTGCGCGGAGGGCGCGGGGGTGGGGCCCGGGGCGGAGCGGCCCGGGGCGGAGGGCGCGGGCTAGCTGAGACTACAGGCGTGCACCATCACGTCCGGCTAATTTTTTGTATTTTAGTAGAGAGGGGGTTTCACCATGTTGGCTAGGATGGTCTCGATCTCCTGCGCTCCACCAGCTTCAGGGGCGGCATGGGGTCCGGGGGCCTGGCCACCGGGATAGCCGGGGGTCTGGCAGGAATGGGAGGCATCCAGAACGAGAAGGAGATCCTCCACCTGGGGGAGAAGAGCATAATAACGTCATTTCCTGCCCTGAAAGCAGCCTCGAGGGCCAACAACACCTGCTGTCCGTGTCCATGCCCGGTTGGTTCCATCCGCGCACCTAGCCACAGGGTCCCTAAGAGCAGCAGCTAGGCATGGGAGGGCTCTTTCCCAGGAGAGAGGGGGAAGGGGACAGGGTTGAGAGCTCCGAGCCGTCCACCTGTGGCTCCGGCTTCCGAAGCGGCTCCGGGGCGGGGGCGGGGCCTCACTCTGCGATATAACTCGGGTCGCGCGGCTCGCGCAGGCCGGAGAAGAAGGGACCCCAGGTCAGAGACTGGAGCCATTACTTCAAGATCATCGAGGACCTGAGGGCTCAGGTAAGGGGTAGGAGGGACCTCAACTCCCAGGGGCTCTGTCCAGGCGCCCAGCTACGGCGCCCGGCCGGTCAGCAGCGCGGCCAGCGTCTATGCAGGCGCTGGGGGCTCTGGTTCCCGGATCTCCGTGTCCAGAGTCTCACTCTGTCGCCAGGCTGCAGTGGCGCGATCTCGGCTCACTGCAACCTCCGCCTCCCAGGTTCAAGCGATTCCCCTTCCTCAGCCTCCCAAGTACCTCGTGATCCGCCCACCTAGGCCTCCCAAAGTGCTGAGATTACAGGCGTGAGCCACTGCGCCCGGTCAAGACTCCCAAATTTCAAACTCGCCAGCACCCAGGTTAAGGACAGCTAGAGGGACTCACAGGCCATTCCACCCGCACACCACCAGACCCCCAAATTTCTTTTTTCTTTTTTTTTTTTTTTTTTTTTGAGACGATGTGGCTAAGGCTGAGTCATCTAGGAGTAAACAAGAGGCCTTCCTTTGGGAGGAGCCAATCCAGGGTGTAGGGGGCCCAGAGTGACCAGGTGCACTAGCCATGCAAAGCCTGAACGACCGCCTGGCCTCTTACCTGGACAGAGTGAGGAGCCTGGAGACCGAGAACCGGAGGCTGGAGAGCAAAATCCGGGAGCACTTTTACAGAGGAAGTGGACAGCATGGAGGGAGGTAAGGAAAGGCCTGTAAAGAGGAGGAGACACTGGCTCTGGCGGAATGGGGACTATTGGAGGGTTAAGCGGCCACCGTCGTCCGCAAAGCCTGAGTCCTGTCCTTTCTCTCTCCCCGGACAGCATGAGCTTCACCACTCGCTCCACCTTCTCCACCAACTACCGGTCCCTGGAAAAAATGCCAGGAGAGGGCCAGGAAGAGGACTTGTTAGTAGCGACTCACTTCTGGGCAGGCAGGCCAGCCAGCTAGCCAGCCTGCTGAGGCTTCCCA',\n",
       " 'promoter_presence': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16db0a5d-7aec-4d59-b44b-d22ff43045fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens:  GGGC TCAGAG ACTGGG TTTGTTTT GGGG AGTC TGCACC TATTTGC TGAGTG AATG TATGTGTG TGTGC ATTTGAG AGCACACC TCTGTATG ATTC GGGTGTG AGTGTGTGTG AGG AAACG TGGGC AGGCG AGGAGTG TTTGGG AGCC AGGTGC AGCTGGGG TGTG AGTGTG TAAGC AAGC AGCTATG AGGCTGGGC ATTGC TTCTCC TCCTCTTC TCCAGC TCCCAGCC TTTC TTCCCC GGG ACTCC TGGGGC TCCAGG ATGCC CCCAAG ATCCCC TCC ACAAG TGGATAA TTTGGGC TGCC TTGTCTG ACCCTCC AATT ATACAC TCC TTTGCC TCTTTCC G TCATTCC ATAACC ACCC AACCCC TAC TCCACC GGG AGGGGG TTGGGC ATACC TGGATCC ACCCC GTTTC TGGGGGG TGAGC GGGGC TTGGC AGGGCTGC GCGG AGGGC GCGG GGG TGGGGCCC GGGGC GGAGC GGCCC GGGGC GG AGGGCGC GGGC TAGCTGAGAC TACAGGC GTGC ACCATC ACG TCCGGC TAATTTTTTGTATT TTAGTAG AGAGGGGG TTTCACCATGTTGGC TAGGATGG TCTCGATCTCC TGCGC TCCACC AGCTTC AGGGGC GGC ATGGGG TCCGG GGGCC TGGCC ACCGGG ATAGCC GGGGG TCTGGC AGG AATGGG AGGCATCC AGAACG AGAAGG AGATCC TCCACC TGGGGG AGAAG AGCATAA TAACG TCATT TCCTGCCC TGAA AGCAGCC TCG AGGGCC AACAAC ACCTGC TGTCC GTGTCC ATGCCC GG TTGGTTCC ATCC GCGC ACCTAGCC ACAGGG TCCCTAAG AGCAGC AGCTAGGC ATGGG AGGGC TCTT TCCCAGG AGAG AGGGGG AAGGGG ACAGGG TTGAGAGC TCCG AGCCG TCCACC TGTGGC TCCGGC TTCCG AAGC GGCTCC GGGGC GG GGGCGG GGCC TCAC TCTGCG ATAT AACTCGGG TCGC GCGGC TCGCGC AGGCCGG AGAAG AAGGG ACCCC AGGTCAGAG ACTGG AGCC ATTAC TTCAAG ATC ATCG AGGACC TGAGGGC TCAGG TAAGGGG TAGGAGGG ACCTC AACTCCC AGGGGC TCTG TCCAGGC GCCC AGCTAC GGC GCCCGGCC GG TCAGC AGCGC GGCC AGCG TCTATGC AGGCGC TGGGGGC TCTGG TTCCCGG ATCTCC GTG TCCAGAG TCTCACTCTG TCGCC AGGCTGC AGTGGC GCGATCTCGGC TCACTGCAACCTCCGCC TCCCAGGTTCAAGCG ATTCCCC TTCC TCAGCCTCCCAAG TACC TC GTGATCC GCCCACC TAGGCC TCCCAAAGTGCTGAG ATTACAGGCGTGAGCC ACTGCGCCC GG TCAAGAC TCCC AAATT TCAAAC TCGCC AGCACCC AGG TTAAGG ACAGC TAGAGGG ACTCAC AGGCC ATTCC ACCCGC ACACC ACC AGACCCCC AAATT TCTTTT TTC TTTTTTTTTTTTTTTTTTTT TGAGACG ATGTGGC TAAGGC TGAGTC ATCTAGG AGTAA ACAAG AGGCC TTCC TTTGGG AGGAGCC AATCC AGGG TGTAG GGGGCCC AGAG TGACC AGG TGCAC TAGCC ATGC AAAGCC TGAACG ACCGCC TGGCC TCTTACC TGGAC AGAG TGAGG AGCC TGGAG ACCG AGAACC GG AGGCTGGAG AGCAAAA TCC GGGAGC ACTTTT ACAG AGGAAG TGGACAGC ATGG AGGGAGG TAAGG AAAGGCC TGTAA AGAGG AGGAG ACACTGGC TCTGGC GG AATGGGG ACTATTGG AGGG TTAAGC GGCC ACCG TCG TCCGC AAAGCC TGAGTCC TGTCC TTTCTCTC TCCCCGG ACAGC ATG AGCTTC ACCACTC GC TCCACC TTCTCC ACCAAC TACCGG TCCC TGGAAAA AATGCC AGGAG AGGGCC AGGAAG AGGACTTG TTAG TAGCG ACTCAC TTCTGGGC AGGCAGGCC AGCCAGC TAGCC AGCCTGC TGAGGC TTCCC A\n"
     ]
    }
   ],
   "source": [
    "print('tokens: ', ' '.join(tokenizer.tokenize(dataset['train'][0]['sequence'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9876c07a-6332-40cc-aa84-2d26e6a3a5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# tokens:  344\n"
     ]
    }
   ],
   "source": [
    "print('# tokens: ', len(tokenizer.tokenize(dataset['train'][0]['sequence'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61840549-83c0-4fec-917c-850bf1a7a357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sequence', 'label'],\n",
       "        num_rows: 10656\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sequence', 'label'],\n",
       "        num_rows: 1184\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.rename_column(\"promoter_presence\", \"label\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46e912af-1aab-4ed2-8007-0f3f970b2255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766e05886ea84052b127d7ed5d662474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10656 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6260b5735e474d4387992d8ede933a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1184 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. tokenize\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['sequence'], truncation=True, padding='max_length', max_length=1024)\n",
    "\n",
    "# 3. 对数据集应用分词函数\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# 4. 创建一个数据收集器，用于动态填充和遮蔽\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afd6f48f-5524-4740-b8ea-54a79fd79dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sequence', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 10656\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sequence', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1184\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1b708bb-21e4-416d-b191-79f302ca4e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.19.90, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'accuracy': (predictions==labels).sum() / len(labels)}\n",
    "\n",
    "# change training hyperparameters to archive better quality\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"ds_job_dna_eng_1_run\",\n",
    "    learning_rate=1e-5,\n",
    "    lr_scheduler_type=\"constant_with_warmup\",\n",
    "    warmup_ratio=0.1,\n",
    "    optim='adamw_torch',\n",
    "    weight_decay=0.0,\n",
    "    per_device_train_batch_size=40,\n",
    "    per_device_eval_batch_size=40,\n",
    "    num_train_epochs=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "082754e6-53fc-4a95-9d1e-887c42975d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2670' max='2670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2670/2670 1:21:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.639900</td>\n",
       "      <td>0.480039</td>\n",
       "      <td>0.774493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.431900</td>\n",
       "      <td>0.447300</td>\n",
       "      <td>0.798142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.316500</td>\n",
       "      <td>0.482207</td>\n",
       "      <td>0.809122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.243400</td>\n",
       "      <td>0.375102</td>\n",
       "      <td>0.854730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>0.459049</td>\n",
       "      <td>0.829392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.525342</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.073600</td>\n",
       "      <td>1.140752</td>\n",
       "      <td>0.798142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.850573</td>\n",
       "      <td>0.831926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>1.370116</td>\n",
       "      <td>0.825169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>1.416664</td>\n",
       "      <td>0.831081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2670, training_loss=0.2147740356931079, metrics={'train_runtime': 4872.7282, 'train_samples_per_second': 21.869, 'train_steps_per_second': 0.548, 'total_flos': 5.568756348616704e+16, 'train_loss': 0.2147740356931079, 'epoch': 10.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9d1eb-6fc6-451f-b596-870ccaa81d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
