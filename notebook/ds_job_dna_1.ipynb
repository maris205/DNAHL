{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29888eda-2755-4add-af9c-8927afb07db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maris/miniconda3/envs/dnagpt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/maris/miniconda3/envs/dnagpt/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tokenizers import Tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained('human_gpt2-v1')\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# if tokenizer.pad_token is None:\n",
    "#     tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "new_tokenizer = Tokenizer.from_file(\"dna_eng_bpe_dict.json\")\n",
    "#或者下面方法\n",
    "from transformers import GPT2TokenizerFast\n",
    "tokenizer = GPT2TokenizerFast(tokenizer_object=new_tokenizer)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75e3778d-9cbb-48c4-8203-0f71f485a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = AutoModel.from_pretrained('gpt_dna_v0')\n",
    "#model.config.eos_token_id\n",
    "# print(model.config.pad_token_id)\n",
    "#model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be845310-8215-4434-bb92-d44c343f274e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers.models.gpt2.modeling_gpt2\n"
     ]
    }
   ],
   "source": [
    "gena_module_name = full_model.__class__.__module__\n",
    "print(gena_module_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb9ee647-cac2-4475-ac44-2f11aef99735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "# available class names:\n",
    "# - BertModel, BertForPreTraining, BertForMaskedLM, BertForNextSentencePrediction,\n",
    "# - BertForSequenceClassification, BertForMultipleChoice, BertForTokenClassification,\n",
    "# - BertForQuestionAnswering\n",
    "# check https://huggingface.co/docs/transformers/model_doc/bert\n",
    "myclass = importlib.import_module(gena_module_name)\n",
    "#dir(myclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62ebfcc0-5d46-4c3b-b462-a3842a985e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.gpt2.modeling_gpt2.GPT2ForSequenceClassification"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = getattr(importlib.import_module(gena_module_name), 'GPT2ForSequenceClassification')\n",
    "cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4523e9b6-3613-41e4-b81d-c139d044e70c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt_dna_v0 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = cls.from_pretrained('gpt_dna_v0', num_labels=2)\n",
    "#dir(model)\n",
    "#model.config.eos_token_id\n",
    "#print(model.config.pad_token_id)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "#model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd024199-16e6-4eb1-b404-c49dc535469b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since yurakuratov/example_promoters_2k couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /home/maris/.cache/huggingface/datasets/yurakuratov___example_promoters_2k/default/0.0.0/78939766a636f4b4b852ef3affbcb0bbb2f84e5b (last modified on Tue Aug 13 12:06:03 2024).\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# load ~11k samples from promoters prediction dataset\n",
    "dataset = load_dataset(\"yurakuratov/example_promoters_2k\")['train'].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3a5213d-66f0-4d17-876c-de4426145412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sequence', 'promoter_presence'],\n",
       "        num_rows: 10656\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sequence', 'promoter_presence'],\n",
       "        num_rows: 1184\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36a23870-1f56-466e-b2bb-c5047072b8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'GCGCTGAAGAAAGAACACCTGAATCCGGAGCCCCAGCCCCCGTCGCTCGTTTGCGCGACCCCAAAACCTGGCGGGACGAGGGTCGCCCGATGTCTAGCTGGAGGAGTTTGGGCTTGGCGCCTCCTTCGTGTAGTGGCTGAAGCTTCCCGGGTGCTCCTCATTCCTGGGAAGGGAGTCGGGTGATGGGAACGGTGGGAGCTCAGCGCTCCGAGTCTGCGGCCGGGGGCCAGCGGGGCTGAAACGCGCCTCCTGAGTGTTGAAAGCGGCAGGCGCCGGCCTTTGCACCCAGAGGCCAGGGCGGACGGGCAGGATAAGCAGGCACTGGGCCCAAGCCGCCCTTGGAGGCTCTGCCTGTTCTGATCTGAAGGCGGAGGCTCAGCCGTGCTCTCCCAGGAAGCCAGCGTGTGACCTTCCAGCCCGCGGACCGATGCTGCCGGCGGCCGCTCGCCCCCTGTGGGGGCCTTGCCTTGGGCTTCGGGCCGCTGCGTTCCGCCTTGCCACCTGGGCGTTTGGGGCTTTAGCTAGGAAAGAGGATGTCGCCTGCGGCTGCGAAGGCGCCAAAGCCCAGACCTCGCGCCTCCGCCCGCGACGGCGGCACTGGGGGCCCGGAGCGGGCGGGAGACGTGGATTACTGCGGGCTTCGGGGCCCTAGCCTCGACCGCGACGTTCGCTCGCATCGCGTACGGACAGAAACCCGTGATCTGAGAACCCTGGACTGGGACCAAGGAGCTAGGTAATTTCCGGCCCTAGTGATTACCAGCCTGAGCTTATGGCACCCACCAGTCCCCCAGTTGTCCTGCAGGTTTGAGTGGTATGGCTGCAAATAAACACGTGGCTTTCTAAGGCTCTTTGAAGAATTTAAAGTAACTTGCAAATCTTATCAATACGGACCCCTTGAGGTCTCACTCACCTTCACATCCAGGCCTCTTAGGGGAGCGCGGCTTTGGCTTTTCCAGGAAGGAATGGACTCCAACGGACAGGGAAAGAAGAAGTGTGGAGAAGGGGCCCCCATGTTTTGGGAGGCTTTGCGCAGGAAGATGCACCTAAGTAATAGTTTCGCCACCGCTGGGTTGATGTAGTTCATTCAAACCAGAAACTTGGGTACGCGGGATCCTGGGGCGGTCCGGGCCGGCAGGCGGGTTAGGGGGCAGCCGGGCACTGAGGGGTCGATCCGGGCGAGGAGGGCGGCGGGGCCGGCCTAGGACATCGCCAGCCTCACTCTCTTGGAAATCTCAGACCTCAACGAGCTCCTGAAGGTATCGTGAGAGGGTGGCACAGACCCAGGGGCTGGAAGTTTCAGGGGGTCGGCCCCAGATGACCTTGGACGATTCCCTGCTCCTCCCTTGGCCTCAGCCTTTTCCGCAGCAAAGGCCCATCCGTGGGTGCGGCGTTTTGCGGCCCGGCTCGAATGCCCGGCAGCCGTGGCGGCTAGAGCGTTCCTCCCCAGCTCGAATGCCCGGCGGCCGAGGCGGCTAGAGCGTCGCCTCCTCCCGGGGAACCCCGCCACAGACGACGCTTTTGCGTCTGCGCAGCGCGCCGCCTTGTGGGTAATCTCAGGGTGAGACGAGGCTAGCGCGAGGTACGGCTAGAGCGTCATTTCCCCTGCAGCGGCCAGGCCGGGCTTGGGGGTCCCATCGGGGGCGCGGGGAGGAGGCCTCCCGGTGCGCACGCCCCTTCCCTCCTGGGCCGTGGAAAGCGCCCCCTCTGGTTTCTGCAGCCCCTTCCATTCCAGGACTGACAAGTCTGTTTTAATTGGGGGTGGGGGCTAGGCGACAGGTGCCATGTGTCTGTGCCGTGCGACATATGAGGAGCAGCGGCCATCAGAGGTGTGAGGCCCTCGCTGGTGCACCCCTGGATAACGCCCCCAAGGAGTACCCCCCCAAGATACAGCAGCTGGTCCCTGCAGGCAGGGTCATTTCCAGCCTGCCCCTCCCTGAGGCTGCGTGCCAGGGTTCATGTGTGCCCTCCGCGGCTCTGCACTGACCCCGCCGGTAGCTGGG',\n",
       " 'promoter_presence': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19e22500-c1e0-444e-9b5c-2a1a2af81997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# base pairs:  2000\n"
     ]
    }
   ],
   "source": [
    "print('# base pairs: ', len(dataset['train'][0]['sequence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16db0a5d-7aec-4d59-b44b-d22ff43045fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens:  GCGC TGAAG AAAG AACACC TGAA TCCGG AGCCCC AGCC CCCG TCGC TCG TTTGC GCG ACCCC AAAACC TGGCGGG ACG AGGG TCG CCCG ATGTC TAGCTGG AGGAG TTTGGGC TTGGC GCC TCCTTC GTG TAGTGGC TGAAGC TTCCC GGGTGC TCCTC ATTCC TGGGAAGGG AGTCGGG TGATGGG AACGG TGGGAGC TCAGCGC TCCG AGTCTGC GGCCGG GGGCC AGC GGGGC TGAAAC GCGCC TCCTG AGTGTTG AAAGC GGC AGGCGCC GGCC TTTGC ACCC AGAGGCC AGGGCGG ACGGGC AGG ATAAGC AGGC ACTGGG CCC AAGCC GCCC TTGGAGGC TCTGCC TGTTC TGATC TGAAGGC GGAGGC TCAGCC GTGC TCTCCC AGGAAGCC AGCG TGTG ACCTTCC AGCCC GCGG ACCG ATGCTGCC GGC GGCCGC TCGCC CCC TGTGGG GGCC TTGCC TTGGGC TTC GGGCC GC TGCG TTCCGCC TTGCCACC TGGGCG TTTGGGGC TTTAGC TAGG AAAGAGG ATGTC GCCTGC GGC TGCG AAGGC GCC AAAGCCC AGACCTC GCGCC TCCGCCC GCG ACGGC GGC ACTGGGGG CCCGG AGCGGGC GGGAGAC GTGG ATTACTGC GGGC TTC GGGGCCC TAGCC TCGACC GCG ACG TTCGC TCGC ATC GCG TACGG ACAGAA ACCC GTGATC TGAGAA CCC TGGAC TGGG ACCAAGG AGC TAGGTAA TTTCC GGCCC TAGTGATT ACCAGCC TGAGC TTATGGC ACCCACC AGTCCCCC AGTTG TCCTGC AGGTTTG AGTGG TATGGC TGC AAATAA ACACG TGGCTTTC TAAGGC TCTTTG AAG AATTTAA AGTAAC TTGC AAATC TTATC AATACGG ACCCC TTGAGG TCTC ACTCACC TTCACATCC AGGCC TCTT AGGGG AGCGC GGC TTTGGC TTTTCC AGGAAGG AATGG ACTCC AACGG ACAGGG AAAG AAGAAG TGTGG AGAAGG GGCCCCC ATGTTTT GGGAGGC TTTGCGC AGGAAG ATGCACC TAAG TAATAG TTTCGCC ACCGC TGGGTTG ATGTAG TTCATTC AAACC AGAA ACTTGGG TACGC GGGATCC TGGGGC GGTCC GGGCC GGC AGGCGGG TTAGGG GGC AGCCGGGC ACTG AGGGG TCG ATCC GGGC GAGG AGGGCGGC GGGGCC GGCC TAGG ACATC GCCAGCC TCACTCTC TTGGAAATC TCAG ACCTC AACG AGCTCCTG AAGG TATCG TGAG AGGGTGGC ACAGACCC AGGGGC TGGAAG TTTC AGGGGG TCGGCCCC AGATG ACCTTGG ACG ATTCCC TGCTCC TCCC TTGGCC TCAGCC TTTTCC GCAGC AAAGGCCC ATCCG TGGGTGC GGCG TTTTGC GGCCC GGC TCG AATG CCCGGC AGCCG TGGC GGCTAG AGCG TTCCTCCCC AGCTCG AATG CCCGGC GGCC GAGGC GGCTAG AGCG TCGCC TCCTCCC GGGG AACCCC GCC ACAGACG ACGC TTTTGCG TCTGCGC AGCGC GCCGCC TTG TGGGTAA TCTCAGGG TGAGAC GAGGC TAGC GCG AGGTAC GGCTAG AGCG TCATT TCCCC TGCAGC GGCC AGGCCGGGC TTGGGGG TCCC ATCGG GGGCGC GGGG AGGAGGCC TCCCGG TGCGC ACGCCCC TTCCCTCC TGGGCC GTGG AAAGC GCCCCC TCTGG TTTCTGC AGCCCC TTCCATTCC AGGAC TGACAAG TCTGTTTT AATTGG GGG TGGGGGC TAGGCG ACAGG TGCC ATGTGTC TGTGCCG TGCG ACATATG AGGAGCAGC GGCC ATCAGAGG TGTG AGGCCC TCGC TGGTGC ACCCC TGGATAAC GCCCCC AAGG AGTACCCC CCCAAG ATAC AGCAGC TGG TCCCTGC AGGCAGGG TCATT TCCAGCC TGCCCC TCCC TGAGGC TGCGTGCC AGGG TTCATG TGTGCCC TCCGC GGC TCTGC ACTG ACCCC GCCGG TAGCTGGG\n"
     ]
    }
   ],
   "source": [
    "print('tokens: ', ' '.join(tokenizer.tokenize(dataset['train'][0]['sequence'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9876c07a-6332-40cc-aa84-2d26e6a3a5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# tokens:  367\n"
     ]
    }
   ],
   "source": [
    "print('# tokens: ', len(tokenizer.tokenize(dataset['train'][0]['sequence'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c4b0442-5fdf-4845-8bf2-4c3b6cc86e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████| 10656/10656 [00:00<00:00, 26511.79 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████| 1184/1184 [00:00<00:00, 25737.79 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_labels(example):\n",
    "  example['label'] = example['promoter_presence']\n",
    "  return example\n",
    "\n",
    "dataset = dataset.map(preprocess_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46e912af-1aab-4ed2-8007-0f3f970b2255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "  # just truncate right, but for some tasks symmetric truncation from left and right is more reasonable\n",
    "  # set max_length to 128 to make experiments faster\n",
    "  return tokenizer(examples[\"sequence\"], truncation=True, max_length=512) #max_length 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ef16794-71fd-4404-a51e-b55b5cae9aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████| 10656/10656 [00:01<00:00, 6178.19 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████| 1184/1184 [00:00<00:00, 7033.50 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "765c199b-9d13-4fd2-ac51-1e5d154766fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afd6f48f-5524-4740-b8ea-54a79fd79dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sequence', 'promoter_presence', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 10656\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sequence', 'promoter_presence', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1184\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1b708bb-21e4-416d-b191-79f302ca4e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maris/miniconda3/envs/dnagpt/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "\n",
    "#tokenizer.pad_token = tokenizer.eos_token \n",
    "#tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'accuracy': (predictions==labels).sum() / len(labels)}\n",
    "\n",
    "# change training hyperparameters to archive better quality\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"ds_job_dna_1_run\",\n",
    "    learning_rate=1e-5,\n",
    "    lr_scheduler_type=\"constant_with_warmup\",\n",
    "    warmup_ratio=0.1,\n",
    "    optim='adamw_torch',\n",
    "    weight_decay=0.0,\n",
    "    per_device_train_batch_size=20,\n",
    "    per_device_eval_batch_size=20,\n",
    "    num_train_epochs=40,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "082754e6-53fc-4a95-9d1e-887c42975d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21320' max='21320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21320/21320 2:59:49, Epoch 40/40]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.697300</td>\n",
       "      <td>0.587714</td>\n",
       "      <td>0.692568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.508700</td>\n",
       "      <td>0.431638</td>\n",
       "      <td>0.793074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.399622</td>\n",
       "      <td>0.820101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.278700</td>\n",
       "      <td>0.503666</td>\n",
       "      <td>0.818412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.177200</td>\n",
       "      <td>0.577425</td>\n",
       "      <td>0.823480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>0.667173</td>\n",
       "      <td>0.833615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>1.082993</td>\n",
       "      <td>0.847128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.050900</td>\n",
       "      <td>1.427295</td>\n",
       "      <td>0.820946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>1.225509</td>\n",
       "      <td>0.834459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>1.741163</td>\n",
       "      <td>0.827703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>1.362096</td>\n",
       "      <td>0.828547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>1.744721</td>\n",
       "      <td>0.826014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>2.339274</td>\n",
       "      <td>0.801520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>1.796532</td>\n",
       "      <td>0.824324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>1.644560</td>\n",
       "      <td>0.834459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>1.547198</td>\n",
       "      <td>0.841216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>1.624957</td>\n",
       "      <td>0.815878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>1.449701</td>\n",
       "      <td>0.836993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>1.802494</td>\n",
       "      <td>0.830236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>1.533476</td>\n",
       "      <td>0.838682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>1.797894</td>\n",
       "      <td>0.825169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>1.710803</td>\n",
       "      <td>0.827703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>1.724493</td>\n",
       "      <td>0.820101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>1.774968</td>\n",
       "      <td>0.818412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>1.969604</td>\n",
       "      <td>0.815034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.760007</td>\n",
       "      <td>0.830236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>1.614228</td>\n",
       "      <td>0.830236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>2.352882</td>\n",
       "      <td>0.823480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>1.676523</td>\n",
       "      <td>0.833615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>1.734618</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>1.653696</td>\n",
       "      <td>0.838682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>1.850361</td>\n",
       "      <td>0.817568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>1.645298</td>\n",
       "      <td>0.842061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>1.316110</td>\n",
       "      <td>0.840372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>1.458889</td>\n",
       "      <td>0.839527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>1.744946</td>\n",
       "      <td>0.842061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>1.548169</td>\n",
       "      <td>0.847973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>1.584363</td>\n",
       "      <td>0.840372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>1.867340</td>\n",
       "      <td>0.826014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>1.426835</td>\n",
       "      <td>0.846284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=21320, training_loss=0.07788993775509089, metrics={'train_runtime': 10790.8244, 'train_samples_per_second': 39.5, 'train_steps_per_second': 1.976, 'total_flos': 8.200294908670771e+16, 'train_loss': 0.07788993775509089, 'epoch': 40.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9d1eb-6fc6-451f-b596-870ccaa81d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9742feb-12f4-4dae-90ce-6c6bec6dd1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
