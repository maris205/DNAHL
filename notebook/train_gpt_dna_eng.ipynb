{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2653cda-096c-4b0f-b6de-78014a975840",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/maris/miniconda3/envs/transformer/lib/python3.10/site-packages/bitsandbytes-0.39.1-py3.10.egg/bitsandbytes/libbitsandbytes_cpu.so\n",
      "False\n",
      "/home/maris/miniconda3/envs/transformer/lib/python3.10/site-packages/bitsandbytes-0.39.1-py3.10.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: /home/maris/miniconda3/envs/transformer did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/maris/miniconda3/envs/transformer/lib/python3.10/site-packages/bitsandbytes-0.39.1-py3.10.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: /home/maris/ros2_ws/install/mavros/lib:/home/maris/ros2_ws/install/custom_msgs/lib:/home/maris/dev_ws/install/learning_interface/lib:/opt/ros/foxy/opt/yaml_cpp_vendor/lib:/opt/ros/foxy/opt/rviz_ogre_vendor/lib:/opt/ros/foxy/lib/x86_64-linux-gnu:/opt/ros/foxy/lib did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/maris/miniconda3/envs/transformer/lib/python3.10/site-packages/bitsandbytes-0.39.1-py3.10.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/home/maris/ros2_ws/install/mavlink/lib/aarch64-linux-gnu/pkgconfig')}\n",
      "  warn(msg)\n",
      "/home/maris/miniconda3/envs/transformer/lib/python3.10/site-packages/bitsandbytes-0.39.1-py3.10.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/home/maris/miniconda3/envs/transformer/lib/python3.10/site-packages/bitsandbytes-0.39.1-py3.10.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('BASH_ENV/u')}\n",
      "  warn(msg)\n",
      "/home/maris/miniconda3/envs/transformer/lib/python3.10/site-packages/bitsandbytes-0.39.1-py3.10.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('unix')}\n",
      "  warn(msg)\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA exception! Error code: no CUDA-capable device is detected\n",
      "CUDA exception! Error code: initialization error\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "/home/maris/miniconda3/envs/transformer/lib/python3.10/site-packages/bitsandbytes-0.39.1-py3.10.egg/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: No GPU detected! Check your CUDA paths. Proceeding to load CPU-only library...\n",
      "  warn(msg)\n",
      "CUDA SETUP: Detected CUDA version 123\n",
      "CUDA SETUP: Required library version not found: libbitsandbytes_cpu.so. Maybe you need to compile it from source?\n",
      "CUDA SETUP: Defaulting to libbitsandbytes_cpu.so...\n",
      "\n",
      "================================================ERROR=====================================\n",
      "CUDA SETUP: CUDA detection failed! Possible reasons:\n",
      "1. CUDA driver not installed\n",
      "2. CUDA not installed\n",
      "3. You have multiple conflicting CUDA libraries\n",
      "4. Required library not pre-compiled for this bitsandbytes release!\n",
      "CUDA SETUP: If you compiled from source, try again with `make CUDA_VERSION=DETECTED_CUDA_VERSION` for example, `make CUDA_VERSION=113`.\n",
      "CUDA SETUP: The CUDA version for the compile might depend on your conda install. Inspect CUDA version via `conda list | grep cuda`.\n",
      "================================================================================\n",
      "\n",
      "CUDA SETUP: Something unexpected happened. Please compile from source:\n",
      "git clone git@github.com:TimDettmers/bitsandbytes.git\n",
      "cd bitsandbytes\n",
      "CUDA_VERSION=123_nomatmul\n",
      "python setup.py install\n",
      "CUDA SETUP: Setup Failed!\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maris/miniconda3/envs/transformer/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/home/maris/miniconda3/envs/transformer/lib/python3.10/runpy.py\", line 146, in _get_module_details\n",
      "    return _get_module_details(pkg_main_name, error)\n",
      "  File \"/home/maris/miniconda3/envs/transformer/lib/python3.10/runpy.py\", line 110, in _get_module_details\n",
      "    __import__(pkg_name)\n",
      "  File \"/home/maris/miniconda3/envs/transformer/lib/python3.10/site-packages/bitsandbytes-0.39.1-py3.10.egg/bitsandbytes/__init__.py\", line 6, in <module>\n",
      "    from . import cuda_setup, utils, research\n",
      "  File \"/home/maris/miniconda3/envs/transformer/lib/python3.10/site-packages/bitsandbytes-0.39.1-py3.10.egg/bitsandbytes/research/__init__.py\", line 1, in <module>\n",
      "    from . import nn\n",
      "  File \"/home/maris/miniconda3/envs/transformer/lib/python3.10/site-packages/bitsandbytes-0.39.1-py3.10.egg/bitsandbytes/research/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import LinearFP8Mixed, LinearFP8Global\n",
      "  File \"/home/maris/miniconda3/envs/transformer/lib/python3.10/site-packages/bitsandbytes-0.39.1-py3.10.egg/bitsandbytes/research/nn/modules.py\", line 8, in <module>\n",
      "    from bitsandbytes.optim import GlobalOptimManager\n",
      "  File \"/home/maris/miniconda3/envs/transformer/lib/python3.10/site-packages/bitsandbytes-0.39.1-py3.10.egg/bitsandbytes/optim/__init__.py\", line 6, in <module>\n",
      "    from bitsandbytes.cextension import COMPILED_WITH_CUDA\n",
      "  File \"/home/maris/miniconda3/envs/transformer/lib/python3.10/site-packages/bitsandbytes-0.39.1-py3.10.egg/bitsandbytes/cextension.py\", line 20, in <module>\n",
      "    raise RuntimeError('''\n",
      "RuntimeError: \n",
      "        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n",
      "\n",
      "        python -m bitsandbytes\n",
      "\n",
      "        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n",
      "        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n",
      "        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues\n"
     ]
    }
   ],
   "source": [
    "#!python -m bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69565362-a932-4be7-a083-5902e3c6d5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maris/miniconda3/envs/dnagpt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig\n",
    "from transformers import GPT2Tokenizer,GPT2Model,AutoModel\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import LineByLineTextDataset\n",
    "\n",
    "from tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c982701-4078-4e2a-8976-2f335177295f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maris/miniconda3/envs/dnagpt/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#ç„¶åŽæˆ‘ä»¬å¯ä»¥ä½¿ç”¨from_file() æ–¹æ³•ä»Žè¯¥æ–‡ä»¶é‡Œé‡æ–°åŠ è½½ Tokenizer å¯¹è±¡ï¼š\n",
    "new_tokenizer = Tokenizer.from_file(\"dna_eng_bpe_dict.json\")\n",
    "#æˆ–è€…ä¸‹é¢æ–¹æ³•\n",
    "from transformers import GPT2TokenizerFast\n",
    "tokenizer = GPT2TokenizerFast(tokenizer_object=new_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93fe531f-28be-4018-b62c-3a850688017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_ctx=128,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "model = GPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb0c71f-a2eb-4f2c-a946-3bcc4c4817e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maris/miniconda3/envs/dnagpt/lib/python3.11/site-packages/transformers/data/datasets/language_modeling.py:119: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_file = \"human2.fna.line.train\"\n",
    "eval_file = \"human2.fna.line.valid\"\n",
    "max_seq_length = 512\n",
    "out_model_path = \"gpt_dna_v0\"\n",
    "train_epoches = 10\n",
    "batch_size = 20\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=train_file,\n",
    "    block_size=max_seq_length,\n",
    ")\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "eval_dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=eval_file,\n",
    "    block_size=max_seq_length,\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=out_model_path,\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=train_epoches,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        save_steps=2000,\n",
    "        save_total_limit=2,\n",
    "        prediction_loss_only=True,\n",
    "        #fp16=True, v100æ²¡æ³•ç”¨\n",
    "    )\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39674ddf-68ee-42dc-af05-485311c8f19d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(out_model_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(out_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "077b7101-c2fe-489b-bf97-a90f1d8e4c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 4754.71\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a1bb64-d798-49c5-867f-79f1fbe16189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
