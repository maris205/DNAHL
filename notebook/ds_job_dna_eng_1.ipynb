{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29888eda-2755-4add-af9c-8927afb07db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maris/miniconda3/envs/dnagpt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/maris/miniconda3/envs/dnagpt/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tokenizers import Tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained('human_gpt2-v1')\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# if tokenizer.pad_token is None:\n",
    "#     tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "new_tokenizer = Tokenizer.from_file(\"dna_eng_bpe_dict.json\")\n",
    "#或者下面方法\n",
    "from transformers import GPT2TokenizerFast\n",
    "tokenizer = GPT2TokenizerFast(tokenizer_object=new_tokenizer)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75e3778d-9cbb-48c4-8203-0f71f485a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = AutoModel.from_pretrained('gpt_dna_eng_v0')\n",
    "#model.config.eos_token_id\n",
    "# print(model.config.pad_token_id)\n",
    "#model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be845310-8215-4434-bb92-d44c343f274e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers.models.gpt2.modeling_gpt2\n"
     ]
    }
   ],
   "source": [
    "gena_module_name = full_model.__class__.__module__\n",
    "print(gena_module_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb9ee647-cac2-4475-ac44-2f11aef99735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "# available class names:\n",
    "# - BertModel, BertForPreTraining, BertForMaskedLM, BertForNextSentencePrediction,\n",
    "# - BertForSequenceClassification, BertForMultipleChoice, BertForTokenClassification,\n",
    "# - BertForQuestionAnswering\n",
    "# check https://huggingface.co/docs/transformers/model_doc/bert\n",
    "myclass = importlib.import_module(gena_module_name)\n",
    "#dir(myclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62ebfcc0-5d46-4c3b-b462-a3842a985e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.gpt2.modeling_gpt2.GPT2ForSequenceClassification"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = getattr(importlib.import_module(gena_module_name), 'GPT2ForSequenceClassification')\n",
    "cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4523e9b6-3613-41e4-b81d-c139d044e70c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt_dna_eng_v0 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = cls.from_pretrained('gpt_dna_eng_v0', num_labels=2)\n",
    "#dir(model)\n",
    "#model.config.eos_token_id\n",
    "#print(model.config.pad_token_id)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "#model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd024199-16e6-4eb1-b404-c49dc535469b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since yurakuratov/example_promoters_2k couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /home/maris/.cache/huggingface/datasets/yurakuratov___example_promoters_2k/default/0.0.0/78939766a636f4b4b852ef3affbcb0bbb2f84e5b (last modified on Tue Aug 13 17:18:14 2024).\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# load ~11k samples from promoters prediction dataset\n",
    "dataset = load_dataset(\"yurakuratov/example_promoters_2k\")['train'].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3a5213d-66f0-4d17-876c-de4426145412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sequence', 'promoter_presence'],\n",
       "        num_rows: 10656\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sequence', 'promoter_presence'],\n",
       "        num_rows: 1184\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36a23870-1f56-466e-b2bb-c5047072b8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'GCCTCAGTCTCCCCATCTGCAAAGGAAGGGCTGGGCTTTCCAGGCCCCAGTGCTGCATCTGATGAATGGTGCCTGGATTAGGAAAGATTCTGAGCTGCTCTGGATGCAGTGGATGAAGCTCTGTGGCTGAGGAATGGTGCTTGCCTGGGCGAGGCTGGAGCAGGCACCTTGGGCGGGGAGGCGTGCGCCAGCCTTCCCTGCATTGAGTGATCTCTGAGGGGTCTTCCAACGGTGAGGCTTGATCATGAGGTAGAGTGCCCCATCTCCGAATGAGGGTGAGTGGCCGTGGGTTGGAGTGCTGGTGAGGGCCCTTGAACCTGTGCTTTTGAGTGCCGATTTGCAGCAGTCTACATCTCATCACCACCTGGGACTGCAGGGGCTTGGGACCAAAAGGATTGCAGTGCCACGCACACAGTCAGGCCTCAGGTCTTGGTGTTGTGGGGCACTGGTTTCACCCCTACAGCCCAGCCTGGAAGCTTCACTCCTGAAAGGCTGTGTAACCATCACAGTGACTCAATCTTCCTAGGCTTCCGTCTGCTCATCTGGAAAATGGGGATAATAATCACAGTGTGATGGAAGGGATTAAATGAATCAGTTTATTAAAGCTCTTAGAAGAGCACGTGGCAGGTAGTAAGCACTTGATAGATACTGAGTGCTGTGTTCGTGCCTCGTGAGGCGCCCCAGCTAGCTGAACAGTCTCTGCATGGGGGATGGGGGCTGTTGGCGCCTCCCCCTCCGAGTCCCTATGTCTTACCCTGGGTGATGCAGGCGCCTGCACTCTCCCTTCCGGTCAGTGCTTTCTTGGTGTCTGGGAATGTGGGTCCAGGCCTTGCCCTGAGCTCCTCCCGGATGTCACCGAAACCTGAGAAGCCCAGGGCCTCAGGGCAGTGGGCATGGGGCATCCAGTTCCATCCGGAAGCACCTCCCGGTGACTCCTGGACCCCACCCTTAGGTCACGTGGCAGCTGCCGTCTGGCATCCTCTCTAAAAGCTCCCAGCCCAGGTCCTGGTCTGTTCTTCAAGTGGACTGGTCGCTGGGAGGCTGCGTCTGTAGGCACTGTGGCCAGCAGGAAAGCAGGGATCTCCGGGGGTCTGCCGGGCCCGTGCTCTCTCCCCACTGCCTGCTCTCTCCCTCCTGGGTTTGCTTCACTGCCCCTTGGTGTTGAAACCGCCTTGTCTAGCTCAGGTAGTGTACCCCAGCGCCCCTCTCCCATTCCCCTCCCGGCGACCCTGGGACCCTGGCAGGCCAACCTGGGTGTCTGCGGAAAACGGTCCTACCTTTAGTAGTGAGCACCTTGTCTTGGCCCTTGAATTGCTTTGTGACCTGGGACAAGTCTCTTTTTCTTTTTGGACTTGGTTCTCCCATCTGTGAAATGGGGAGCCAGCCTTCTTGCTTGCTAAGGCCTCTTCCAGCAAAACAGTTTCTCTGATTTCATGTCTTGTCTGATTTCACTGTATGCACCCCATTGAGCAAGAGCCAAAAAGGCCTGTGTGTCCCTGGTGGAGGATATTGTCCTATATTTCTTATATTGCGACCTTGAAGGCCGCATGGTTGTGTAACATCTTGCCACACCTGTGTTTACGCAGGAGTGTTCTTGAGACATTGTCTAGCTTGTGGTGCTAGGGTTTCTATGCCAGGGTCCCCTTCTGGGTCTGTCTTTGTGGTGCTGTATTCACCAAGTGCCCAGTGAGGGGGCTCCCAGCACCCCTGGGGAGGGTTTCTCTCTCTCTCTCTCTCACACACACACACACGCACACACGGCAGAGCAGGGCTGTGTGAGGCTGAGGACTGACATTCTGGGCTCCAACTCTCTCTTCTGCTCAGTTTCCAGGGGTCCTGGGACAGGTGTCTTTGTCAGTTTTTGGCTCTGAGAAATGAGGGAGTGGGGCATGAACTTGACCTTGTTGATGCTCTCTGTGTGGTAAAACCACGCAGAGAGGAACGTCGACAGAAGTGGGGGTTTCCAAGCCTGTATGACACCATCTGGGCAGGTCTGCGGT',\n",
       " 'promoter_presence': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19e22500-c1e0-444e-9b5c-2a1a2af81997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# base pairs:  2000\n"
     ]
    }
   ],
   "source": [
    "print('# base pairs: ', len(dataset['train'][0]['sequence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16db0a5d-7aec-4d59-b44b-d22ff43045fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens:  GCC TCAGTC TCCCC ATCTGC AAAGG AAGGGC TGGGC TTTCC AGGCCCC AGTGC TGCATC TGATG AATGG TGCCTGG ATTAGG AAAGATTC TGAGCTGC TCTGG ATGC AGTGG ATGAAGC TCTGTGGC TGAGG AATGGTGC TTGCC TGGGCG AGGCTGG AGCAGGC ACCTTGGGC GGGG AGGC GTGCGCC AGCC TTCCC TGCATTG AGTG ATCTCTG AGGGG TCTTCC AACGG TGAGGC TTG ATCATG AGGTAG AGTGCCCC ATC TCCG AATGAGGG TGAG TGGCCG TGGGTTGG AGTGCTGG TGAGGG CCC TTGAACC TGTGC TTTTG AGTGCCG ATTTGC AGC AGTCTAC ATCTC ATCACC ACCTGGG ACTGC AGGGGC TTGGG ACC AAAAGG ATTGC AGTGCC ACGC ACACAGTC AGGCC TCAGG TCTTGG TGTTG TGGGGC ACTGG TTTC ACCCCTAC AGCCCAGCC TGGAAGC TTCACTCC TGAA AGGCTGTG TAACC ATCAC AGTGACTC AATCTTCC TAGGC TTCCG TCTGC TCATC TGGAAAA TGGGG ATAATAA TCAC AGTGTG ATGG AAGGG ATTAAATG AATC AGTTTATT AAAGC TCTTAG AAGAGC ACGTGGC AGGTAG TAAGC ACTTG ATAGATAC TGAG TGCTGTG TTCG TGCC TCGTG AGGC GCCCC AGCTAGC TGAAC AGTCTC TGC ATGGGGG ATGGGGGC TGTTGGC GCC TCCCCC TCCG AGTCCC TATG TCTT ACCCTGGG TGATGC AGGCGCC TGCACTC TCCCTTCC GG TCAG TGCTTTC TTGGTGTC TGGGAATG TGGGTCC AGGCC TTGCCC TGAGC TCCTCCC GGATG TCACCG AAACC TGAG AAGCCC AGGGCC TCAGGGC AGTGGGC ATGGGGC ATCC AGTTCC ATCC GGAAGC ACCTCCC GGTGAC TCCTGG ACCCCACCC TTAGG TCACG TGGCAGC TGCCG TCTGGC ATCCTCTC TAAAAGC TCCC AGCCCAGG TCCTGG TCTGTTC TTCAAG TGGACTGG TCGC TGGGAGGC TGCG TCTGTAGGC ACTGTGGCC AGCAGG AAAGCAGGG ATCTCC GGGGG TCTGCC GGGCCC GTGC TCTCTCCCC ACTGCC TGCTCTC TCCC TCCTGGG TTTGC TTCAC TGCCCC TTGG TGTTG AAACC GCC TTGTC TAGC TCAGGTAG TGTACCCC AGC GCCCC TCTCCC ATTCCCC TCCC GGCG ACCCTGGG ACCCTGGC AGGCC AACCTGGG TGTC TGCGG AAAACGG TCCTACC TTTAGTAG TGAGCACC TTGTC TTGGCCC TTG AATTGC TTTGTG ACCTGGG ACAAG TCTCTTTT TCTTTT TGGAC TTGG TTCTCCC ATCTGTG AAATGGGG AGCCAGCC TTCTTGC TTGCTAA GGCC TCTTCC AGCAAAAC AGTTTC TCTG ATTTCATG TCTTGTCTG ATTTCAC TGTATGC ACCCC ATTG AGCAAG AGCCAAAA AGGCC TGTG TGTCCC TGG TGGAGG ATATTG TCC TATATTTC TTATATT GCG ACCTTG AAGGCC GC ATGGTTG TGTAAC ATCTTGCC ACACC TGTGTTTAC GC AGGAGTG TTCTTG AGACATTG TCTAGC TTG TGGTGC TAGGG TTTC TATGCC AGGG TCCCC TTCTGGG TCTG TCTTTG TGGTGC TGTATTC ACCAAG TGCCC AGTG AGGGGGC TCCCAGC ACCCC TGGGG AGGGTTTC TCTCTCTCTCTCTCTC ACACACACACAC ACGCACAC ACGGC AGAGC AGGGCTGTG TGAGGC TGAGG ACTGAC ATTC TGGGC TCCAAC TCTC TCTTCTGC TCAGTTTCC AGGGG TCCTGGG ACAGG TGTCTTTG TCAGTTTT TGGCTCTG AGAAATG AGGG AGTGGGGC ATGAAC TTGACC TTGTTG ATGC TCTCTGTG TGGTAA AACC ACGC AGAGAGG AACG TCG ACAGAAG TGGGGG TTTCC AAGCC TGTATG ACACC ATCTGGGC AGGTCTGC GG T\n"
     ]
    }
   ],
   "source": [
    "print('tokens: ', ' '.join(tokenizer.tokenize(dataset['train'][0]['sequence'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9876c07a-6332-40cc-aa84-2d26e6a3a5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# tokens:  339\n"
     ]
    }
   ],
   "source": [
    "print('# tokens: ', len(tokenizer.tokenize(dataset['train'][0]['sequence'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c4b0442-5fdf-4845-8bf2-4c3b6cc86e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████| 10656/10656 [00:00<00:00, 28682.70 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████| 1184/1184 [00:00<00:00, 27950.70 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_labels(example):\n",
    "  example['label'] = example['promoter_presence']\n",
    "  return example\n",
    "\n",
    "dataset = dataset.map(preprocess_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46e912af-1aab-4ed2-8007-0f3f970b2255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "  # just truncate right, but for some tasks symmetric truncation from left and right is more reasonable\n",
    "  # set max_length to 128 to make experiments faster\n",
    "  return tokenizer(examples[\"sequence\"], truncation=True, max_length=512) #max_length 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ef16794-71fd-4404-a51e-b55b5cae9aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████| 10656/10656 [00:01<00:00, 6072.82 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████| 1184/1184 [00:00<00:00, 8370.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "765c199b-9d13-4fd2-ac51-1e5d154766fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afd6f48f-5524-4740-b8ea-54a79fd79dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sequence', 'promoter_presence', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 10656\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sequence', 'promoter_presence', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1184\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1b708bb-21e4-416d-b191-79f302ca4e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maris/miniconda3/envs/dnagpt/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "\n",
    "#tokenizer.pad_token = tokenizer.eos_token \n",
    "#tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'accuracy': (predictions==labels).sum() / len(labels)}\n",
    "\n",
    "# change training hyperparameters to archive better quality\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"ds_job_dna_eng_1_run\",\n",
    "    learning_rate=1e-5,\n",
    "    lr_scheduler_type=\"constant_with_warmup\",\n",
    "    warmup_ratio=0.1,\n",
    "    optim='adamw_torch',\n",
    "    weight_decay=0.0,\n",
    "    per_device_train_batch_size=20,\n",
    "    per_device_eval_batch_size=20,\n",
    "    num_train_epochs=40,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "082754e6-53fc-4a95-9d1e-887c42975d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21320' max='21320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21320/21320 3:04:50, Epoch 40/40]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.724500</td>\n",
       "      <td>0.590316</td>\n",
       "      <td>0.701858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.481600</td>\n",
       "      <td>0.394340</td>\n",
       "      <td>0.810811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.365600</td>\n",
       "      <td>0.341261</td>\n",
       "      <td>0.838682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.293500</td>\n",
       "      <td>0.421001</td>\n",
       "      <td>0.822635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>0.406183</td>\n",
       "      <td>0.847128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.154400</td>\n",
       "      <td>0.551899</td>\n",
       "      <td>0.837838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.109100</td>\n",
       "      <td>0.893241</td>\n",
       "      <td>0.815878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>1.187016</td>\n",
       "      <td>0.825169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.461942</td>\n",
       "      <td>0.829392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>1.739270</td>\n",
       "      <td>0.830236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.042900</td>\n",
       "      <td>2.036195</td>\n",
       "      <td>0.813345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>1.940903</td>\n",
       "      <td>0.828547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>2.102285</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>1.649446</td>\n",
       "      <td>0.836993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>1.614100</td>\n",
       "      <td>0.828547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>1.937196</td>\n",
       "      <td>0.827703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>2.230017</td>\n",
       "      <td>0.826858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>1.868506</td>\n",
       "      <td>0.826858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>2.128072</td>\n",
       "      <td>0.833615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>2.271572</td>\n",
       "      <td>0.820946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>2.419885</td>\n",
       "      <td>0.816723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>2.218913</td>\n",
       "      <td>0.818412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>2.520227</td>\n",
       "      <td>0.820946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>2.198829</td>\n",
       "      <td>0.823480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>2.477942</td>\n",
       "      <td>0.829392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>2.739433</td>\n",
       "      <td>0.802365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>1.906070</td>\n",
       "      <td>0.818412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>2.142006</td>\n",
       "      <td>0.822635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>1.974805</td>\n",
       "      <td>0.834459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>2.156187</td>\n",
       "      <td>0.826858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.026300</td>\n",
       "      <td>2.165206</td>\n",
       "      <td>0.833615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>1.955745</td>\n",
       "      <td>0.816723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>2.092387</td>\n",
       "      <td>0.831081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>2.086231</td>\n",
       "      <td>0.816723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.882436</td>\n",
       "      <td>0.837838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>1.747378</td>\n",
       "      <td>0.828547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>2.014960</td>\n",
       "      <td>0.826858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>2.535195</td>\n",
       "      <td>0.816723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.029200</td>\n",
       "      <td>1.647272</td>\n",
       "      <td>0.833615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>2.032073</td>\n",
       "      <td>0.831926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=21320, training_loss=0.0842922910964064, metrics={'train_runtime': 11091.677, 'train_samples_per_second': 38.429, 'train_steps_per_second': 1.922, 'total_flos': 8.20187085469778e+16, 'train_loss': 0.0842922910964064, 'epoch': 40.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9d1eb-6fc6-451f-b596-870ccaa81d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
